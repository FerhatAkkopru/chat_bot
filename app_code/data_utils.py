import json
import pickle
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import uuid
import os

# Dosya yollarÄ± (webhook.py'nin bulunduÄŸu dizine gÃ¶re ../data/ olmalÄ±
# ya da proje kÃ¶kÃ¼nden Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yorsa data/ olabilir.
# Mevcut yapÄ±ya gÃ¶re data/ varsayÄ±yoruz, app_code ve data kardeÅŸ dizinler)
BASE_DATA_PATH = "data"
DATA_JSON = os.path.join(BASE_DATA_PATH, "datas.json")
EMBEDDINGS_FILE = os.path.join(BASE_DATA_PATH, "embeddings.npy")
METADATA_FILE = os.path.join(BASE_DATA_PATH, "metadata.pkl")
FAISS_FILE = os.path.join(BASE_DATA_PATH, "faiss_index.index")

# Modelin tekrar yÃ¼klenmesini Ã¶nlemek iÃ§in global bir deÄŸiÅŸken
_model_instance = None

def get_sentence_transformer_model():
    global _model_instance
    if _model_instance is None:
        _model_instance = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    return _model_instance

def _ensure_data_dir_exists():
    os.makedirs(BASE_DATA_PATH, exist_ok=True)

def load_data():
    _ensure_data_dir_exists()
    if not os.path.exists(DATA_JSON):
        return []
    try:
        with open(DATA_JSON, "r", encoding="utf-8") as f:
            content = f.read()
            if not content: # Dosya boÅŸsa
                return []
            return json.loads(content)
    except json.JSONDecodeError:
        print(f"âš ï¸ '{DATA_JSON}' dosyasÄ± Ã§Ã¶zÃ¼mlenemedi, boÅŸ liste dÃ¶ndÃ¼rÃ¼lÃ¼yor.")
        return [] # Bozuk JSON durumunda boÅŸ liste dÃ¶ndÃ¼r

def save_data(data):
    _ensure_data_dir_exists()
    with open(DATA_JSON, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_metadata():
    _ensure_data_dir_exists()
    if not os.path.exists(METADATA_FILE) or os.path.getsize(METADATA_FILE) == 0:
        return []
    try:
        with open(METADATA_FILE, "rb") as f:
            return pickle.load(f)
    except pickle.UnpicklingError:
        print(f"âš ï¸ '{METADATA_FILE}' dosyasÄ± Ã§Ã¶zÃ¼mlenemedi, boÅŸ liste dÃ¶ndÃ¼rÃ¼lÃ¼yor.")
        return [] # Bozuk pickle durumunda
    except EOFError: # Dosya beklenenden Ã¶nce biterse (boÅŸ veya Ã§ok kÄ±sa)
        print(f"âš ï¸ '{METADATA_FILE}' dosyasÄ± okunurken EOFError, boÅŸ liste dÃ¶ndÃ¼rÃ¼lÃ¼yor.")
        return []


def save_metadata(metadata):
    _ensure_data_dir_exists()
    with open(METADATA_FILE, "wb") as f:
        pickle.dump(metadata, f)

def load_embeddings():
    _ensure_data_dir_exists()
    model = get_sentence_transformer_model() # Model embedding boyutunu almak iÃ§in
    embedding_dim = model.get_sentence_embedding_dimension()
    if not os.path.exists(EMBEDDINGS_FILE):
        # FAISS iÃ§in float32 tipinde boÅŸ bir 2D array dÃ¶ndÃ¼r
        return np.empty((0, embedding_dim), dtype=np.float32)
    try:
        embeddings = np.load(EMBEDDINGS_FILE)
        # YÃ¼klenen embeddinglerin beklenen boyutta olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        if embeddings.ndim == 2 and embeddings.shape[1] == embedding_dim:
            return embeddings.astype(np.float32)
        elif embeddings.size == 0: # Dosya var ama boÅŸ numpy array'i iÃ§eriyor
             return np.empty((0, embedding_dim), dtype=np.float32)
        else:
            print(f"âš ï¸ '{EMBEDDINGS_FILE}' iÃ§indeki embeddinglerin boyutu ({embeddings.shape}) beklenenden farklÄ± ({embedding_dim}). BoÅŸ array dÃ¶ndÃ¼rÃ¼lÃ¼yor.")
            return np.empty((0, embedding_dim), dtype=np.float32)
    except ValueError as e: # Numpy dosyasÄ± bozuksa
        print(f"âš ï¸ '{EMBEDDINGS_FILE}' yÃ¼klenirken hata: {e}. BoÅŸ array dÃ¶ndÃ¼rÃ¼lÃ¼yor.")
        return np.empty((0, embedding_dim), dtype=np.float32)


def save_embeddings(embeddings):
    _ensure_data_dir_exists()
    np.save(EMBEDDINGS_FILE, embeddings.astype(np.float32))

def update_faiss_index(embeddings):
    _ensure_data_dir_exists()
    if not isinstance(embeddings, np.ndarray) or embeddings.ndim != 2 or embeddings.shape[0] == 0:
        print("âš ï¸ FAISS index oluÅŸturmak iÃ§in geÃ§erli embedding bulunamadÄ±.")
        if os.path.exists(FAISS_FILE): # GeÃ§ersiz durumda eski indeksi sil
            try:
                os.remove(FAISS_FILE)
                print(f"ğŸ—‘ï¸ Eski FAISS index dosyasÄ± '{FAISS_FILE}' silindi.")
            except OSError as e:
                print(f"ğŸš¨ Eski FAISS index dosyasÄ± '{FAISS_FILE}' silinirken hata: {e}")
        return

    dimension = embeddings.shape[1]
    # FAISS iÃ§in C-contiguous ve float32 olduÄŸundan emin ol
    embeddings_for_faiss = np.ascontiguousarray(embeddings, dtype=np.float32)
    faiss.normalize_L2(embeddings_for_faiss) # VeritabanÄ± embeddinglerini normalize et
    index = faiss.IndexFlatIP(dimension)
    index.add(embeddings_for_faiss)
    faiss.write_index(index, FAISS_FILE)
    print(f"âœ… FAISS index gÃ¼ncellendi ve '{FAISS_FILE}' dosyasÄ±na kaydedildi. Toplam {index.ntotal} vektÃ¶r.")


def get_answer_by_id(record_id):
    metadata = load_metadata()
    for item in metadata:
        if item.get("id") == record_id: # Daha gÃ¼venli eriÅŸim iÃ§in .get() kullan
            return item.get("cevap") # Cevap yoksa None dÃ¶ner
    return None

def add_question(soru, cevap):
    model = get_sentence_transformer_model() # PaylaÅŸÄ±lan model Ã¶rneÄŸini al
    new_id = str(uuid.uuid4())
    # Sorunun string olduÄŸundan emin ol, encode iÃ§in liste iÃ§inde ver
    new_embedding_single = model.encode([str(soru)], convert_to_numpy=True).astype(np.float32)

    data = load_data()
    metadata = load_metadata()
    current_embeddings = load_embeddings()

    data.append({"id": new_id, "soru": soru, "cevap": cevap})
    metadata.append({"id": new_id, "soru": soru, "cevap": cevap})

    if current_embeddings.shape[0] == 0:
        updated_embeddings = new_embedding_single # Zaten (1, dim) ÅŸeklinde olmalÄ±
    else:
        # new_embedding_single'Ä±n (1, dim) ÅŸeklinde olduÄŸundan emin ol
        if new_embedding_single.ndim == 1: # encode bazen 1D dÃ¶nebilir, 2D'ye Ã§evir
             new_embedding_single = np.expand_dims(new_embedding_single, axis=0)
        updated_embeddings = np.vstack([current_embeddings, new_embedding_single])

    save_data(data)
    save_metadata(metadata)
    save_embeddings(updated_embeddings)
    update_faiss_index(updated_embeddings) # Bu fonksiyon artÄ±k boÅŸ embeddingleri de ele alÄ±yor

    print(f"âœ… Yeni soru eklendi: '{soru}' (id: {new_id})")